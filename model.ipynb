{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 948.7546509999999\n",
      "Feature: Magnitude, Importance: 0.11695434799043715\n",
      "Feature: Crime_Types, Importance: 0.03632226241024021\n",
      "Feature: time_of_day, Importance: 0.031726128470444225\n",
      "Feature: shops_nearby, Importance: 0.059480918237693955\n",
      "Feature: area_type, Importance: 0.023006123162832227\n",
      "Feature: has_Vehicle, Importance: 0.011009119495446688\n",
      "Feature: crime_rate, Importance: 0.03141831315324137\n",
      "Feature: number_crime_last_Three_months, Importance: 0.09894819900723421\n",
      "Feature: number_people_accompanying, Importance: 0.042315520197854666\n",
      "Feature: weather_condition, Importance: 0.03490762359471998\n",
      "Feature: proximity_police_station, Importance: 0.11203541636498875\n",
      "Feature: proximity_hospital, Importance: 0.12669649146616574\n",
      "Feature: streetlight, Importance: 0.011972904660990009\n",
      "Feature: traffic_density, Importance: 0.041529521443785654\n",
      "Feature: reported_crimes, Importance: 0.10655696050840836\n",
      "Feature: proximity_public_transport, Importance: 0.11512014983551683\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('dataset/numerical_safe_road_scenarios.csv')\n",
    "\n",
    "# Feature columns (excluding target 'SafeRoad')\n",
    "X = df.drop(columns=['SafeRoad'])\n",
    "\n",
    "# Target column\n",
    "y = df['SafeRoad']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Feature importance\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "for name, importance in zip(feature_names, importances):\n",
    "    print(f'Feature: {name}, Importance: {importance}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safety score for the route: 52.47\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def predict_safety_score(route_segments, model, user_data):\n",
    "    safety_scores = []\n",
    "    \n",
    "    for segment in route_segments:\n",
    "        # Extract necessary features for each segment\n",
    "        segment_data = {\n",
    "            'Magnitude': segment['crime_severity'],  # example of crime data\n",
    "            'Crime_Types': segment['crime_type'],  # example of crime type\n",
    "            'time_of_day': user_data['time_of_day'],\n",
    "            'shops_nearby': segment['shops_nearby'],\n",
    "            'area_type': segment['area_type'],\n",
    "            'has_Vehicle': user_data['has_vehicle'],\n",
    "            'crime_rate': segment['crime_rate'],\n",
    "            'number_crime_last_Three_months': segment['recent_crimes'],\n",
    "            'number_people_accompanying': user_data['number_people_accompanying'],\n",
    "            'weather_condition': segment['weather_condition'],\n",
    "            'proximity_police_station': segment['police_station_distance'],\n",
    "            'proximity_hospital': segment['hospital_distance'],\n",
    "            'streetlight': segment['streetlight'],\n",
    "            'traffic_density': segment['traffic_density'],\n",
    "            'reported_crimes': segment['reported_crimes'],\n",
    "            'proximity_public_transport': segment['public_transport_distance']\n",
    "        }\n",
    "\n",
    "        # Convert data to the appropriate format for prediction (e.g., DataFrame)\n",
    "        input_data = pd.DataFrame([segment_data])\n",
    "\n",
    "        # Predict the safety score for the segment\n",
    "        safety_score = model.predict(input_data)\n",
    "        safety_scores.append(safety_score[0])\n",
    "\n",
    "    # Calculate the average safety score for the entire route\n",
    "    return sum(safety_scores) / len(safety_scores)\n",
    "\n",
    "# Example usage of the function with Google Maps API response\n",
    "user_data = {\n",
    "    'time_of_day': 2,  # Example: Day\n",
    "    'has_vehicle': 1,  # No Vehicle\n",
    "    'number_people_accompanying': 1\n",
    "}\n",
    "\n",
    "# Example list of route segments from Google Maps\n",
    "route_segments = [\n",
    "    {\n",
    "        'crime_severity': 5.0,\n",
    "        'crime_type': 3,\n",
    "        'shops_nearby': 5,\n",
    "        'area_type': 1,\n",
    "        'crime_rate': 2,\n",
    "        'recent_crimes': 10,\n",
    "        'weather_condition': 1,\n",
    "        'police_station_distance': 2.0,\n",
    "        'hospital_distance': 3.5,\n",
    "        'streetlight': 1,\n",
    "        'traffic_density': 3,\n",
    "        'reported_crimes': 25,\n",
    "        'public_transport_distance': 1.2\n",
    "    },\n",
    "    # Additional route segments\n",
    "]\n",
    "\n",
    "safety_score = predict_safety_score(route_segments, model, user_data)\n",
    "print(f'Safety score for the route: {safety_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googlemaps in c:\\users\\adarsh vishwakarma\\.conda\\envs\\texts\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.20.0 in c:\\users\\adarsh vishwakarma\\.conda\\envs\\texts\\lib\\site-packages (from googlemaps) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adarsh vishwakarma\\.conda\\envs\\texts\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adarsh vishwakarma\\.conda\\envs\\texts\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adarsh vishwakarma\\.conda\\envs\\texts\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adarsh vishwakarma\\.conda\\envs\\texts\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "\n",
    "# Initialize the Google Maps client with API key\n",
    "gmaps = googlemaps.Client(key='AIzaSyAaRnCKVVSWGR159MyTF6rV7NMIPsW960c')\n",
    "\n",
    "def get_routes(origin, destination):\n",
    "    # Get routes from Google Maps Directions API\n",
    "    directions = gmaps.directions(origin, destination, mode=\"driving\", alternatives=True)\n",
    "\n",
    "    # Extract steps (route segments)\n",
    "    routes = []\n",
    "    for route in directions:\n",
    "        for step in route['legs'][0]['steps']:\n",
    "            routes.append({\n",
    "                'start_location': step['start_location'],\n",
    "                'end_location': step['end_location'],\n",
    "                'distance': step['distance']['text'],\n",
    "                'duration': step['duration']['text']\n",
    "            })\n",
    "    \n",
    "    return routes\n",
    "\n",
    "# Example of fetching routes between two places\n",
    "origin = \"1600 Amphitheatre Parkway, Mountain View, CA\"\n",
    "destination = \"1 Infinite Loop, Cupertino, CA\"\n",
    "routes = get_routes(origin, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of route segments: 39\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of route segments: {len(routes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('prediction_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save label encoders\n",
    "# with open('label_encoders.pkl', 'wb') as f:\n",
    "#     pickle.dump(label_encoders, f)\n",
    "\n",
    "print(\"Best model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Magnitude', 'Crime_Types', 'time_of_day', 'shops_nearby', 'area_type',\n",
       "       'has_Vehicle', 'crime_rate', 'number_crime_last_Three_months',\n",
       "       'number_people_accompanying', 'weather_condition',\n",
       "       'proximity_police_station', 'proximity_hospital', 'streetlight',\n",
       "       'traffic_density', 'reported_crimes', 'proximity_public_transport',\n",
       "       'SafeRoad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
